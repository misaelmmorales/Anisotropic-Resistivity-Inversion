{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated anisotropic resistivity inversion for efficient formation evaluation and uncertainty quantification\n",
    "\n",
    "### Misael M. Morales, Michael Pyrcz, Carlos Torres-Verdin, 2024\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:00:29.669546200Z",
     "start_time": "2024-02-09T04:00:29.611739Z"
    }
   },
   "outputs": [],
   "source": [
    "from main import *\n",
    "ari = ARI()\n",
    "case1, case2 = ari.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv1 = ari.resistivity_inversion(case1, lambda_reg=1e-6, Wd_matrix=True, tolerance=1e-6, maxiter=1e3, \n",
    "                                    x0=[0.5, 1.5], Rvsh=2.8133, Rhsh=0.7746, \n",
    "                                    method='CG', bounds=None)\n",
    "ari.plot_inversion_results(inv1, figsize=(20,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv2 = ari.resistivity_inversion(case2, lambda_reg=1e-6, Wd_matrix=True, tolerance=1e-6, maxiter=1e3, \n",
    "                                    x0=[0.5, 1.5], Rvsh=4.0431, Rhsh=0.6742, \n",
    "                                    method='CG', bounds=None)\n",
    "ari.plot_inversion_results(inv2, figsize=(20,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv1 = ari.resistivity_inversion(case1, lambda_reg=1e-6, Wd_matrix=True, tolerance=1e-6, maxiter=1e3, \n",
    "                                    x0=[0.5, 1.5], Rvsh=2.8133, Rhsh=0.7746, \n",
    "                                    method='L-BFGS-B', bounds=[(0,1),(None,None)])\n",
    "ari.plot_inversion_results(inv1, figsize=(20,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv2 = ari.resistivity_inversion(case2, lambda_reg=1e-6, Wd_matrix=True, tolerance=1e-6, maxiter=1e3, \n",
    "                                    x0=[0.5, 1.5], Rvsh=4.0431, Rhsh=0.6742, \n",
    "                                    method='L-BFGS-B', bounds=[(0,1),(None,None)])\n",
    "ari.plot_inversion_results(inv2, figsize=(20,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1_qinv = ari.quadratic_inversion(case1)\n",
    "case2_qinv = ari.quadratic_inversion(case2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.2.0 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3080\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "ari = ARI()\n",
    "case1, case2 = ari.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT10</th>\n",
       "      <th>AT30</th>\n",
       "      <th>AT60</th>\n",
       "      <th>AT90</th>\n",
       "      <th>GR</th>\n",
       "      <th>Rv</th>\n",
       "      <th>Rh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9650.00</th>\n",
       "      <td>1.0775</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>103.6210</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650.25</th>\n",
       "      <td>1.0791</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>0.7406</td>\n",
       "      <td>105.2029</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650.50</th>\n",
       "      <td>1.0807</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>106.7848</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650.75</th>\n",
       "      <td>1.0823</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>105.9264</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651.00</th>\n",
       "      <td>1.0840</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>105.0679</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10248.50</th>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>94.9540</td>\n",
       "      <td>2.9869</td>\n",
       "      <td>0.6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10248.75</th>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>95.6692</td>\n",
       "      <td>3.5105</td>\n",
       "      <td>0.6583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249.00</th>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>96.3843</td>\n",
       "      <td>4.0340</td>\n",
       "      <td>0.6642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249.25</th>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.7243</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>95.9892</td>\n",
       "      <td>4.0340</td>\n",
       "      <td>0.6642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249.50</th>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.7194</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>95.5940</td>\n",
       "      <td>4.0340</td>\n",
       "      <td>0.6642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AT10    AT30    AT60    AT90        GR      Rv      Rh\n",
       "DEPTH                                                             \n",
       "9650.00   1.0775  0.8261  0.7674  0.7382  103.6210  0.7833  0.7833\n",
       "9650.25   1.0791  0.8266  0.7685  0.7406  105.2029  0.7833  0.7833\n",
       "9650.50   1.0807  0.8271  0.7695  0.7429  106.7848  0.7833  0.7833\n",
       "9650.75   1.0823  0.8270  0.7668  0.7438  105.9264  0.7833  0.7833\n",
       "9651.00   1.0840  0.8268  0.7641  0.7448  105.0679  0.7833  0.7833\n",
       "...          ...     ...     ...     ...       ...     ...     ...\n",
       "10248.50  0.9547  0.7695  0.7260  0.7119   94.9540  2.9869  0.6525\n",
       "10248.75  0.9513  0.7688  0.7275  0.7134   95.6692  3.5105  0.6583\n",
       "10249.00  0.9480  0.7681  0.7291  0.7149   96.3843  4.0340  0.6642\n",
       "10249.25  0.9465  0.7641  0.7243  0.7125   95.9892  4.0340  0.6642\n",
       "10249.50  0.9450  0.7601  0.7194  0.7102   95.5940  4.0340  0.6642\n",
       "\n",
       "[2399 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNari(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINNari, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsLoss(nn.Module):\n",
    "    def __init__(self, model, Rvsh, Rhsh):\n",
    "        super(PhysicsLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.Rvsh = Rvsh\n",
    "        self.Rhsh = Rhsh\n",
    "\n",
    "    def forward(self, Rv_true, Rh_true):\n",
    "        Csh, Rs = self.model(torch.tensor([Rv_true, Rh_true], dtype=torch.float32))\n",
    "        Csh = torch.sigmoid(Csh) #Csh in [0,1]\n",
    "        Rs  = torch.abs(Rs)      #Rs in [0,inf)\n",
    "\n",
    "        eq1 = (Csh*self.Rvsh + (1-Csh)*Rs) - Rv_true\n",
    "        eq2 = (Csh/self.Rhsh + (1-Csh)/Rs) - (1/Rh_true)\n",
    "\n",
    "        eq1 = eq1.unsqueeze(0) if eq1.dim() == 0 else eq1\n",
    "        eq2 = eq2.unsqueeze(0) if eq2.dim() == 0 else eq2\n",
    "\n",
    "        eqs = torch.cat((eq1, eq2), dim=0)\n",
    "\n",
    "        return torch.norm(eqs, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_aniso = case1[['Rv','Rh']]\n",
    "Rvsh, Rhsh =2.8133, 0.7746\n",
    "\n",
    "model     = PINNari()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = PhysicsLoss(model, Rvsh, Rhsh)\n",
    "\n",
    "epochs = 20\n",
    "for _, row in res_aniso.iterrows():\n",
    "    Rv_true, Rh_true = row['Rv'], row['Rh']\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(Rv_true, Rh_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "adjoints = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        adjoints[name] = param.grad.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(torch.tensor(case1[['Rv','Rh']].values, dtype=torch.float32))\n",
    "csh_pred = pred[:,1].detach().numpy()\n",
    "rs_pred  = pred[:,0].detach().numpy()\n",
    "sol = pd.DataFrame({'Csh_pred':csh_pred, 'Rs_pred':rs_pred}, index=case1.index)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8), sharey=True)\n",
    "ax1, ax2 = axs\n",
    "\n",
    "ax11 = ax1.twiny()\n",
    "ari.plot_curve(ax1, case1, 'GR', 10, 150, 'g', pad=8)\n",
    "ari.plot_curve(ax11, sol, 'Csh_pred', -1, 2, 'k')\n",
    "\n",
    "\n",
    "ax21, ax22 = ax2.twiny(), ax2.twiny()\n",
    "ari.plot_curve(ax2, case1, 'Rv', 0.02, 200, 'r', semilog=True, pad=8)\n",
    "ari.plot_curve(ax21, case1, 'Rh', 0.02, 200, 'b', semilog=True, pad=16)\n",
    "ari.plot_curve(ax22, sol, 'Rs_pred', 0.02, 200, 'k', semilog=True)\n",
    "\n",
    "[ax.grid(True, which='both') for ax in axs]\n",
    "ax1.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pinnARI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pinnARI, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = torch.tensor(dataframe.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, Rvsh, Rhsh, lambda_reg=1e-6):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.Rvsh = Rvsh\n",
    "        self.Rhsh = Rhsh\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        Rv_true, Rh_true = targets[:, 0], targets[:, 1]\n",
    "\n",
    "        Csh_pred = torch.sigmoid(outputs[:, 0])  # Csh in [0, 1]\n",
    "        Rs_pred  = torch.exp(outputs[:, 1])      # Rs > 0\n",
    "\n",
    "        Rv_sim = Csh_pred * self.Rvsh + (1 - Csh_pred) * Rs_pred\n",
    "        Rh_sim = 1 / (Csh_pred / self.Rhsh + (1 - Csh_pred) / Rs_pred)\n",
    "\n",
    "        v_err = (Rv_sim - Rv_true)**2\n",
    "        h_err = (Rh_sim - Rh_true)**2\n",
    "        t_err = torch.cat([v_err, h_err])\n",
    "\n",
    "        error = torch.mean(t_err) + self.lambda_reg*torch.norm(outputs)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_aniso  = case1[['Rv','Rh']]\n",
    "Rvsh, Rhsh = np.percentile(res_aniso['Rv'], 90), np.percentile(res_aniso['Rh'], 90)\n",
    "\n",
    "dataset    = CustomDataset(res_aniso)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = pinnARI().to(device)\n",
    "criterion = CustomLoss(Rvsh, Rhsh)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "total_loss = []\n",
    "num_epochs, monitor = 300, 20\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        batch   = batch.to(device)\n",
    "        outputs = model(batch)\n",
    "        loss    = criterion(outputs, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    total_loss.append(epoch_loss)\n",
    "    if (epoch+1) % monitor == 0:\n",
    "        print('Epoch [{}/{}] | Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 123\n",
    "\n",
    "u = torch.Tensor(case1[['Rv','Rh']].iloc[row].values).to(device)\n",
    "print(model(u))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(range(num_epochs), total_loss)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
