{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated anisotropic resistivity inversion for efficient formation evaluation and uncertainty quantification\n",
    "\n",
    "### Misael M. Morales, Ali Eghbali, Oriyomi Raheem, Michael Pyrcz, Carlos Torres-Verdin\n",
    "***\n",
    "## PINN-based Inversion (PyTorch)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.1.2.post300 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3080\n",
      "------------------------------------------------------------\n",
      "\n",
      "Name              : Source                : Shape\n",
      "----------------- : --------------------- : -----------\n",
      "Field Case 1      : (Chevron)             : (2399, 12)\n",
      "Field Case 2      : (AkerBP)              : (11143, 12)\n",
      "Synthetic Case 1  : (Laminated)           : (801, 14)\n",
      "Synthetic Case 2  : (Laminated+Dispersed) : (415, 10)\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "\n",
    "check_torch()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "case1, case2, synthetic1, synthetic2 = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Physics-informed neural network inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResInvLoss(nn.Module):\n",
    "    def __init__(self, dd_flag:bool=True, ddmax=100, lambda_reg=1e-5, lambda_p=2):\n",
    "        super(ResInvLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lambda_p   = lambda_p\n",
    "        self.dd_flag    = dd_flag\n",
    "        self.ddmax      = ddmax\n",
    "\n",
    "    def forward(self, inputs, outputs):\n",
    "        Rv_true  = inputs[:, 0]\n",
    "        Rh_true  = inputs[:, 1]\n",
    "        dd_true  = inputs[:, 2]/self.ddmax\n",
    "        Rvsh     = inputs[:, 3]\n",
    "        Rhsh     = inputs[:, 4]\n",
    "        Csh_pred = outputs[:, 0]\n",
    "        Rss_pred = outputs[:, 1]\n",
    "\n",
    "        eq1 = (Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred) - (Rv_true)\n",
    "        eq2 = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred) - (Rh_true)\n",
    "        eqs = torch.stack([eq1, eq2], dim=-1)\n",
    "\n",
    "        if self.dd_flag:\n",
    "            wd1, wd2 = 1/Rv_true/dd_true, 1*Rh_true/dd_true\n",
    "        else:\n",
    "            wd1, wd2 = 1/Rv_true, 1*Rh_true\n",
    "        Wdm = torch.stack([wd1, wd2], dim=-1)\n",
    "\n",
    "        costf = torch.norm(torch.matmul(Wdm.T, eqs), p=2)\n",
    "        regPa = self.lambda_reg*torch.norm(outputs, p=self.lambda_p)\n",
    "\n",
    "        return  costf + regPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoss(nn.Module):\n",
    "    def __init__(self, loss_fn=nn.MSELoss()):\n",
    "        super(DataLoss, self).__init__()\n",
    "        self.dd_loss = loss_fn\n",
    "\n",
    "    def forward(self, inputs, outputs):\n",
    "        Rv_true  = inputs[:, 0]\n",
    "        Rh_true  = inputs[:, 1]\n",
    "        dd_true  = inputs[:, 2]\n",
    "        Rvsh     = inputs[:, 3]\n",
    "        Rhsh     = inputs[:, 4]\n",
    "        Csh_pred = outputs[:, 0]\n",
    "        Rss_pred = outputs[:, 1]\n",
    "        Rv_sim = (Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred)\n",
    "        Rh_sim = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred)\n",
    "        return (self.dd_loss(Rv_sim, Rv_true) + self.dd_loss(Rh_sim, Rh_true))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResInvPINN(nn.Module):\n",
    "    def __init__(self, hidden_dim:int=128, csh_constraint_mult=1.5):\n",
    "        super(ResInvPINN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 2)\n",
    "        self.mult = csh_constraint_mult\n",
    "\n",
    "    def constraints(self, d):\n",
    "        c, s = d[:, 0], d[:, 1]\n",
    "        c = self.mult*torch.sigmoid(c)\n",
    "        return torch.stack([c, s], dim=-1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x[:, :2]\n",
    "        x = self.fc1(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.Tanhshrink()(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.constraints(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CALI', 'AT10', 'AT30', 'AT60', 'AT90', 'GR', 'Rv', 'Rh', 'Rvsh', 'Rhsh']\n",
    "\n",
    "zstart = int(np.argwhere(case1.index==9720).squeeze())\n",
    "zend   = int(np.argwhere(case1.index==10110).squeeze())\n",
    "data1  = case1.iloc[zstart:zend]\n",
    "\n",
    "zstart = int(np.argwhere(case2.index==6292.75).squeeze())\n",
    "zend   = int(np.argwhere(case2.index==9078.25).squeeze())\n",
    "data2  = case2.iloc[zstart:zend]\n",
    "\n",
    "data3 = synthetic1.dropna()\n",
    "data4 = synthetic2.dropna()\n",
    "\n",
    "data_all = pd.concat([data1, data2, data3, data4], ignore_index=False)\n",
    "print('Data_all: {}'.format(data_all.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Chevron 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = 'AT90'\n",
    "res_aniso = data1[['Rv', 'Rh', dd, 'Rvsh', 'Rhsh', 'WIDX']]\n",
    "inputs    = torch.tensor(res_aniso.values, dtype=torch.float32).to(device)\n",
    "print('Inputs: {}'.format(inputs.shape))\n",
    "\n",
    "dataset        = TensorDataset(inputs)\n",
    "train_percent  = 0.85\n",
    "xtrain, xtest  = random_split(dataset, [int(train_percent*len(dataset)), len(dataset)-int(train_percent*len(dataset))])\n",
    "xtrain, xvalid = random_split(xtrain, [int(train_percent*len(xtrain)), len(xtrain)-int(train_percent*len(xtrain))])\n",
    "print('X_train: {} | X_valid: {} | X_test: {}'.format(len(xtrain), len(xvalid), len(xtest)))\n",
    "\n",
    "batch_size  = 32\n",
    "trainloader = DataLoader(xtrain, batch_size=batch_size, shuffle=True)\n",
    "validloader = DataLoader(xvalid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model     = ResInvPINN(hidden_dim=150, csh_constraint_mult=1.75).to(device)\n",
    "criterion = ResInvLoss(ddmax=data1[dd].max(), lambda_reg=1e-10).to(device)\n",
    "mseloss   = DataLoss(loss_fn=nn.MSELoss()).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "print('# of Parameters: {:,}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "epochs, monitor = 501, 100\n",
    "train_loss, valid_loss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    epoch_train_loss = []\n",
    "    model.train()\n",
    "    for i, x in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x[0])\n",
    "        loss = criterion(x[0], y) + mseloss(x[0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss.append(loss.item())\n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    # validation\n",
    "    model.eval()\n",
    "    epoch_valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for x in validloader:\n",
    "            y = model(x[0])\n",
    "            loss = criterion(x[0], y)\n",
    "            epoch_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(epoch_valid_loss))\n",
    "    # progress\n",
    "    if epoch % monitor == 0:\n",
    "        print('Epoch: {} | Loss: {:.4f} | Valid Loss: {:.4f}'.format(epoch, train_loss[-1], valid_loss[-1]))\n",
    "losses = (train_loss, valid_loss)\n",
    "plot_loss(losses)\n",
    "\n",
    "y_pred = model(inputs[:,:2]).cpu().detach().numpy().squeeze()\n",
    "Csh_pred, Rss_pred = [y_pred[:, i] for i in range(y_pred.shape[1])]\n",
    "print('Csh: min={:.3f} | max={:.3f}'.format(Csh_pred.min(), Csh_pred.max()))\n",
    "\n",
    "Rv_true = res_aniso['Rv'].values\n",
    "Rh_true = res_aniso['Rh'].values\n",
    "Rvsh    = res_aniso['Rvsh'].values\n",
    "Rhsh    = res_aniso['Rhsh'].values\n",
    "\n",
    "Rv_sim = (Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred)\n",
    "Rh_sim = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred)\n",
    "\n",
    "Rv_err = np.abs((Rv_sim - Rv_true)/Rv_true) * 100\n",
    "Rh_err = np.abs((Rh_sim - Rh_true)/Rh_true) * 100\n",
    "\n",
    "pinn_sol = pd.DataFrame({'Csh_pred':Csh_pred, 'Rss_pred':Rss_pred, \n",
    "                         'Rv_sim':Rv_sim, 'Rh_sim':Rh_sim,\n",
    "                         'Rv_err':Rv_err, 'Rh_err':Rh_err}, \n",
    "                         index=res_aniso.index)\n",
    "\n",
    "results = pd.concat([data1, pinn_sol], axis=1)\n",
    "results.to_csv('results/pinn_solution_Chevron.csv', index=True)\n",
    "error_metrics(results)\n",
    "\n",
    "s = 'Chevron 2009'\n",
    "plot_pinn_results(results, suptitle=s)\n",
    "gradientbased_results = pd.read_csv('results/gradient_based_solution_Chevron.csv', index_col=0)\n",
    "plot_pinn_gb_comparison(results, gradientbased_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.abs(quadratic_inversion(data1))\n",
    "q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_objective(variables, *args):\n",
    "    Csh, Rss = variables\n",
    "    Rv, Rh, Rvsh, Rhsh = args[0], args[1], args[2], args[3]\n",
    "    eq1 = (Csh*Rvsh + (1-Csh)*Rss) - Rv\n",
    "    eq2 = (Csh/Rhsh + (1-Csh)/Rss) - (1/Rh)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "qinv_results = []\n",
    "for i, row in data1.iterrows():\n",
    "    Rv, Rh, Rvsh, Rhsh = row['Rv'], row['Rh'], row['Rvsh'], row['Rhsh']\n",
    "    result = optimize.newton(func    = quadratic_objective, \n",
    "                             x0      = [0.5, 1],\n",
    "                             args    = (Rv, Rh, Rvsh, Rhsh),\n",
    "                             maxiter = 1000, \n",
    "                             tol     = 1e-6, \n",
    "                             disp    = False)\n",
    "    \n",
    "result\n",
    "    #qinv_results.append(result.x)\n",
    "#qinv_results = pd.DataFrame(qinv_results, columns=['Csh_q', 'Rss_q'], index=data1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8,8), sharey=True)\n",
    "ax1, ax2 = axs\n",
    "\n",
    "ax1.plot(qinv_results['Csh_q'], qinv_results.index, c='k', ls='--', label='Csh_q')\n",
    "ax1.plot(results['Csh_pred'], results.index, c='r', ls='-', label='Csh_pred')\n",
    "ax1.set(xlim=(0,1))\n",
    "\n",
    "ax2.plot(data1['Rv'], data1.index, c='darkred', label='True Rv')\n",
    "ax2.plot(data1['Rh'], data1.index, c='darkblue', label='True Rh')\n",
    "ax2.set(xscale='log')\n",
    "\n",
    "[ax.grid(True, which='both') for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "ax1.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'AkerBP Hanz Prospect'\n",
    "plot_pinn_results(results[data_all['WIDX']==2], suptitle=s)\n",
    "gradientbased_results = pd.read_csv('results/gradient_based_solution_AkerBP.csv', index_col=0)\n",
    "plot_pinn_gb_comparison(results[data_all['WIDX']==2], gradientbased_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Synthetic Case 1 (Laminated)'\n",
    "plot_pinn_results(results[data_all['WIDX']==3], figsize=(12,12), suptitle=s)\n",
    "gradientbased_results = pd.read_csv('results/gradient_based_solution_synthetic1.csv', index_col=0).iloc[22:]\n",
    "plot_pinn_gb_comparison(results[data_all['WIDX']==3], gradientbased_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Synthetic Case 2 (Laminated + Dispersed)'\n",
    "plot_pinn_results(results[data_all['WIDX']==4], suptitle=s)\n",
    "gradientbased_results = pd.read_csv('results/gradient_based_solution_synthetic2.csv', index_col=0)\n",
    "plot_pinn_gb_comparison(results[data_all['WIDX']==4], gradientbased_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = results[data_all['WIDX']==1]\n",
    "r2 = results[data_all['WIDX']==2]\n",
    "synthetic_all = pd.concat([r1, r2], ignore_index=False)\n",
    "s_split = len(r1)\n",
    "print('Synthetic 1: {} | Synthetic 2: {}'.format(r1.shape, r2.shape))\n",
    "print('Synthetic All: {}'.format(synthetic_all.shape))\n",
    "\n",
    "n_realizations = 1000\n",
    "y_preds = np.zeros((n_realizations, synthetic_all.shape[0], 2))\n",
    "for i in range(n_realizations):\n",
    "    \n",
    "    noisy_inputs = inputs + torch.randn_like(inputs)*0.1\n",
    "    y_preds[i] = model(noisy_inputs).cpu().detach().numpy().squeeze()\n",
    "print(y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10.5,6.5))\n",
    "ax1, ax2 = axs\n",
    "titles = ['Chevron2009', 'AkerBP', 'Synthetic 1', 'Synthetic 2']\n",
    "\n",
    "for i in range(50):\n",
    "    Csh_pred, Rss_pred = y_preds[i, :, 0], y_preds[i, :, 1]\n",
    "    Rvsh, Rhsh = results['Rvsh'].values, results['Rhsh'].values\n",
    "    Rvsim = Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred\n",
    "    Rhsim = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred)\n",
    "    ax1.plot(Rvsim[data_all['WIDX']==1], r1.index, c='rosybrown', alpha=0.1)\n",
    "    ax1.plot(Rhsim[data_all['WIDX']==1], r1.index, c='lightsteelblue', alpha=0.1)\n",
    "    ax2.plot(Rvsim[data_all['WIDX']==2], r2.index, c='rosybrown', alpha=0.1)\n",
    "    ax2.plot(Rhsim[data_all['WIDX']==2], r2.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "ax1.plot(r1['Rv'], r1.index, c='k', lw=1, ls='--', label='True Rv')\n",
    "ax1.plot(r1['Rh'], r1.index, c='k', lw=1, ls='-.', label='True Rh')\n",
    "\n",
    "ax2.plot(r2['Rv'], r2.index, c='k', lw=0.5, ls='--', label='True Rv')\n",
    "ax2.plot(r2['Rh'], r2.index, c='k', lw=0.5, ls='-.', label='True Rh')\n",
    "\n",
    "[ax.set_title(titles[i], weight='bold') for i, ax in enumerate(axs)]\n",
    "[ax.set(xscale='log', ylabel='Depth [ft]', xlabel='$R_i$ $[\\Omega\\cdot m]$') for ax in axs]\n",
    "[ax.grid(True, which='both') for ax in axs]\n",
    "[ax.legend(loc='lower left') for ax in axs]\n",
    "ax1.invert_yaxis(); ax2.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
