{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated anisotropic resistivity inversion for efficient formation evaluation and uncertainty quantification\n",
    "\n",
    "### Misael M. Morales, Ali Eghbali, Oriyomi Raheem, Michael Pyrcz, Carlos Torres-Verdin\n",
    "***\n",
    "## PINN-based Inversion (PyTorch)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "check_torch()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "case1, case2, synthetic1, synthetic2 = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Physics-informed neural network inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNLoss(nn.Module):\n",
    "    def __init__(self, dd_flag:bool=True, ddmax=100, lambda_reg=1e-10, lambda_p=2):\n",
    "        super(PINNLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lambda_p   = lambda_p\n",
    "        self.dd_flag    = dd_flag\n",
    "        self.ddmax      = ddmax\n",
    "\n",
    "    def forward(self, inputs, outputs):\n",
    "        Rv_true  = inputs[:, 0]\n",
    "        Rh_true  = inputs[:, 1]\n",
    "        dd_true  = inputs[:, 2]/self.ddmax\n",
    "        Rvsh     = inputs[:, 3]\n",
    "        Rhsh     = inputs[:, 4]\n",
    "        Csh_pred = outputs[:, 0]\n",
    "        Rss_pred = outputs[:, 1]\n",
    "\n",
    "        eq1 = (Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred) - (Rv_true)\n",
    "        eq2 = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred) - (Rh_true)\n",
    "        eqs = torch.stack([eq1, eq2], dim=-1)\n",
    "\n",
    "        if self.dd_flag:\n",
    "            wd1, wd2 = 1/Rv_true/dd_true, 1*Rh_true/dd_true\n",
    "        else:\n",
    "            wd1, wd2 = 1/Rv_true, 1*Rh_true\n",
    "        Wdm = torch.stack([wd1, wd2], dim=-1)\n",
    "\n",
    "        costf = torch.norm(torch.matmul(Wdm.T, eqs), p=2)\n",
    "        regPa = self.lambda_reg*torch.norm(outputs, p=self.lambda_p)\n",
    "\n",
    "        return  costf + regPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoss(nn.Module):\n",
    "    def __init__(self, loss_fn=nn.MSELoss(), lambda_p=2):\n",
    "        super(DataLoss, self).__init__()\n",
    "        self.dd_loss = loss_fn\n",
    "        self.lambda_p = lambda_p\n",
    "\n",
    "    def forward(self, inputs, outputs):\n",
    "        Rv_true  = inputs[:, 0]\n",
    "        Rh_true  = inputs[:, 1]\n",
    "        dd_true  = inputs[:, 2]\n",
    "        Rvsh     = inputs[:, 3]\n",
    "        Rhsh     = inputs[:, 4]\n",
    "        Csh_pred = outputs[:, 0]\n",
    "        Rss_pred = outputs[:, 1]\n",
    "        Rv_sim = (Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred)\n",
    "        Rh_sim = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred)\n",
    "        v_loss = self.dd_loss(Rv_sim, Rv_true)\n",
    "        h_loss = self.dd_loss(Rh_sim, Rh_true)\n",
    "        return torch.norm(torch.stack([v_loss, h_loss], dim=-1), p=self.lambda_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResInvPINN(nn.Module):\n",
    "    def __init__(self, hidden_dim:int=128, csh_constraint_mult=1.0):\n",
    "        super(ResInvPINN, self).__init__()\n",
    "        self.fc1  = nn.Linear(2, hidden_dim)\n",
    "        self.fc2  = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3  = nn.Linear(hidden_dim, 2)\n",
    "        self.mult = csh_constraint_mult\n",
    "\n",
    "    def constraints(self, d):\n",
    "        c, s = d[:, 0], d[:, 1]\n",
    "        c = self.mult*torch.sigmoid(c)\n",
    "        return torch.stack([c, s], dim=-1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x[:, :2]\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = nn.Tanh()(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = nn.Tanhshrink()(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.constraints(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CALI', 'AT10', 'AT30', 'AT60', 'AT90', 'GR', 'Rv', 'Rh', 'Rvsh', 'Rhsh']\n",
    "\n",
    "zstart = int(np.argwhere(case1.index==9720).squeeze())\n",
    "zend   = int(np.argwhere(case1.index==10110).squeeze())\n",
    "data1  = case1.iloc[zstart:zend]\n",
    "\n",
    "zstart = int(np.argwhere(case2.index==6292.75).squeeze())\n",
    "zend   = int(np.argwhere(case2.index==9078.25).squeeze())\n",
    "data2  = case2.iloc[zstart:zend]\n",
    "\n",
    "data3 = synthetic1.dropna()\n",
    "data4 = synthetic2.dropna()\n",
    "\n",
    "data_all = pd.concat([data1, data2, data3, data4], ignore_index=False)\n",
    "print('Data_all: {}'.format(data_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = 'GR'\n",
    "res_aniso = data_all[['Rv','Rh', dd, 'Rvsh', 'Rhsh']].dropna()\n",
    "inputs = torch.tensor(res_aniso.values, dtype=torch.float32).to(device)\n",
    "print('Inputs: {}'.format(inputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset        = TensorDataset(inputs)\n",
    "train_percent  = 0.8\n",
    "n_train        = int(train_percent*len(dataset))\n",
    "xtrain, xvalid = random_split(dataset, [n_train, len(dataset)-n_train])\n",
    "print('X_train: {} | X_valid: {}'.format(len(xtrain), len(xvalid)))\n",
    "\n",
    "batch_size  = 32\n",
    "trainloader = DataLoader(xtrain, batch_size=batch_size, shuffle=True)\n",
    "validloader = DataLoader(xvalid, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = ResInvPINN(hidden_dim=150).to(device)\n",
    "\n",
    "criterion = PINNLoss(ddmax=data_all[dd].max(), lambda_reg=0, dd_flag=True).to(device)\n",
    "mseloss   = DataLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "\n",
    "print('# of Parameters: {:,}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, monitor = 301, 100\n",
    "pinn_lambda = 0.85\n",
    "train_loss, valid_loss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    epoch_train_loss = []\n",
    "    model.train()\n",
    "    for i, x in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x[0])\n",
    "        loss = (pinn_lambda)*criterion(x[0], y) + (1-pinn_lambda)*mseloss(x[0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss.append(loss.item())\n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    # validation\n",
    "    model.eval()\n",
    "    epoch_valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for x in validloader:\n",
    "            y = model(x[0])\n",
    "            loss = (pinn_lambda)*criterion(x[0], y) + (1-pinn_lambda)*mseloss(x[0], y)\n",
    "            epoch_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(epoch_valid_loss))\n",
    "    # progress\n",
    "    if epoch % monitor == 0:\n",
    "        print('Epoch: {} | Loss: {:.4f} | Valid Loss: {:.4f}'.format(epoch, train_loss[-1], valid_loss[-1]))\n",
    "\n",
    "torch.save(model.state_dict(), 'models/model_all.pth')\n",
    "losses = (train_loss, valid_loss)\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(inputs[:,:2]).cpu().detach().numpy().squeeze()\n",
    "Csh_pred, Rss_pred = [y_pred[:, i] for i in range(y_pred.shape[1])]\n",
    "print('Csh:', ' '*15, 'min: {:.3f}  | max: {:.3f}'.format(Csh_pred.min(), Csh_pred.max()))\n",
    "\n",
    "Rv_true = res_aniso['Rv'].values\n",
    "Rh_true = res_aniso['Rh'].values\n",
    "Rvsh    = res_aniso['Rvsh'].values\n",
    "Rhsh    = res_aniso['Rhsh'].values\n",
    "\n",
    "Rv_sim = (Csh_pred*Rvsh + (1-Csh_pred)*Rss_pred)\n",
    "Rh_sim = 1/(Csh_pred/Rhsh + (1-Csh_pred)/Rss_pred)\n",
    "Rv_err = np.abs((Rv_sim - Rv_true)/Rv_true) * 100\n",
    "Rh_err = np.abs((Rh_sim - Rh_true)/Rh_true) * 100\n",
    "\n",
    "Csh_pred_norm = (Csh_pred - Csh_pred.min())/(Csh_pred.max() - Csh_pred.min())\n",
    "pinn_sol = pd.DataFrame({'Csh_pred':Csh_pred_norm, 'Rss_pred':Rss_pred, \n",
    "                         'Rv_sim':Rv_sim, 'Rh_sim':Rh_sim,\n",
    "                         'Rv_err':Rv_err, 'Rh_err':Rh_err}, \n",
    "                         index=res_aniso.index)\n",
    "\n",
    "quad_sol = newton_inversion(res_aniso)\n",
    "\n",
    "results = pd.concat([data_all, pinn_sol, quad_sol], axis=1)\n",
    "results.to_csv('results/pinn_solution_all.csv', index=True)\n",
    "error_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevron_model      = ResInvPINN(hidden_dim=150).to(device)\n",
    "chevron_model.load_state_dict(torch.load('models/model_Chevron.pth'))\n",
    "chevron_results    = pd.read_csv('results/pinn_solution_Chevron.csv', index_col=0)\n",
    "chevron_gb_results = pd.read_csv('results/gradient_based_solution_Chevron.csv', index_col=0)\n",
    "chevron_data       = lasio.read('cases/well1.las').df().loc[chevron_results.index]\n",
    "chevron_all        = chevron_data.merge(chevron_results).set_index(chevron_results.index)\n",
    "\n",
    "akerbp_model       = ResInvPINN(hidden_dim=150).to(device)\n",
    "akerbp_model.load_state_dict(torch.load('models/model_AkerBP.pth'))\n",
    "akerbp_results     = pd.read_csv('results/pinn_solution_AkerBP.csv', index_col=0)\n",
    "akerbp_gb_results  = pd.read_csv('results/gradient_based_solution_AkerBP.csv', index_col=0)\n",
    "akerbp_data        = lasio.read('cases/well2.LAS').df().loc[akerbp_results.index]\n",
    "akerbp_all         = akerbp_data.merge(akerbp_results).set_index(akerbp_results.index)\n",
    "\n",
    "synth1_model       = ResInvPINN(hidden_dim=150).to(device)\n",
    "synth1_model.load_state_dict(torch.load('models/model_synthetic1.pth'))\n",
    "synth1_results     = pd.read_csv('results/pinn_solution_synthetic1.csv', index_col=0)\n",
    "synth1_gb_results  = pd.read_csv('results/gradient_based_solution_synthetic1.csv', index_col=0).iloc[22:]\n",
    "synthetic1_data     = lasio.read('cases/Case1.las').df().join(lasio.read('cases/Case1_RvRh.las').df()).loc[synth1_results.index]\n",
    "synthetic1_all     = synthetic1_data.merge(synth1_results, left_index=True, right_index=True)\n",
    "\n",
    "synth2_model       = ResInvPINN(hidden_dim=150).to(device)\n",
    "synth2_model.load_state_dict(torch.load('models/model_synthetic2.pth'))\n",
    "synth2_results     = pd.read_csv('results/pinn_solution_synthetic2.csv', index_col=0)\n",
    "synth2_gb_results  = pd.read_csv('results/gradient_based_solution_synthetic2.csv', index_col=0)\n",
    "synthetic2_data    = lasio.read('cases/Case2.las').df().loc[synth2_results.index]\n",
    "synthetic2_all     = synthetic2_data.merge(synth2_results).set_index(synth2_results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Chevron 2009'\n",
    "plot_pinn_results(chevron_results, suptitle=s)\n",
    "plot_pinn_gb_comparison(chevron_all, chevron_gb_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'AkerBP Hanz Prospect'\n",
    "plot_pinn_results(akerbp_results, suptitle=s)\n",
    "plot_pinn_gb_comparison(akerbp_all, akerbp_gb_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Synthetic Case 1 (Laminated)'\n",
    "plot_pinn_results(synth1_results, figsize=(12,12), suptitle=s)\n",
    "plot_pinn_gb_comparison(synthetic1_all, synth1_gb_results, suptitle=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Synthetic Case 2 (Laminated + Dispersed)'\n",
    "plot_pinn_results(synth2_results, suptitle=s, at_flag=False)\n",
    "plot_pinn_gb_comparison(synthetic2_all, synth2_gb_results, suptitle=s, at_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations = 1000\n",
    "noise_level = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevron_uq = np.zeros((n_realizations, chevron_results.shape[0], 2))\n",
    "for i in range(n_realizations):\n",
    "    noisy_inputs = chevron_results[['Rv','Rh']] + noise_level*np.random.lognormal(0, 1, size=(chevron_results.shape[0], 2))\n",
    "    noisy_inputs = torch.tensor(noisy_inputs.values, dtype=torch.float32).to(device)\n",
    "    chevron_uq[i] = chevron_model(noisy_inputs).cpu().detach().numpy().squeeze()\n",
    "print(chevron_uq.shape)\n",
    "\n",
    "chevron_uq_csh = np.zeros((n_realizations, chevron_results.shape[0]))\n",
    "for i in range(n_realizations):\n",
    "    c = chevron_uq[i,:,0]\n",
    "    chevron_uq_csh[i] = (c - c.min())/(c.max() - c.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akerbp_uq = np.zeros((n_realizations, akerbp_results.shape[0], 2))\n",
    "for i in range(n_realizations):\n",
    "    noisy_inputs = akerbp_results[['Rv','Rh']] + noise_level*np.random.lognormal(0, 1, size=(akerbp_results.shape[0], 2))\n",
    "    noisy_inputs = torch.tensor(noisy_inputs.values, dtype=torch.float32).to(device)\n",
    "    akerbp_uq[i] = akerbp_model(noisy_inputs).cpu().detach().numpy().squeeze()\n",
    "print(akerbp_uq.shape)\n",
    "\n",
    "akerbp_uq_csh = np.zeros((n_realizations, akerbp_results.shape[0]))\n",
    "for i in range(n_realizations):\n",
    "    c = akerbp_uq[i,:,0]\n",
    "    akerbp_uq_csh[i] = (c - c.min())/(c.max() - c.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic1_uq = np.zeros((n_realizations, synth1_results.shape[0], 2))\n",
    "for i in range(n_realizations):\n",
    "    noisy_inputs = synth1_results[['Rv','Rh']] + noise_level*np.random.lognormal(0, 1, size=(synth1_results.shape[0], 2))\n",
    "    noisy_inputs = torch.tensor(noisy_inputs.values, dtype=torch.float32).to(device)\n",
    "    synthetic1_uq[i] = synth1_model(noisy_inputs).cpu().detach().numpy().squeeze()\n",
    "print(synthetic1_uq.shape)\n",
    "\n",
    "synthetic1_uq_csh = np.zeros((n_realizations, synth1_results.shape[0]))\n",
    "for i in range(n_realizations):\n",
    "    c = synthetic1_uq[i,:,0]\n",
    "    synthetic1_uq_csh[i] = (c - c.min())/(c.max() - c.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic2_uq = np.zeros((n_realizations, synth2_results.shape[0], 2))\n",
    "for i in range(n_realizations):\n",
    "    noisy_inputs = synth2_results[['Rv','Rh']] + noise_level*np.random.lognormal(0, 1, size=(synth2_results.shape[0], 2))\n",
    "    noisy_inputs = torch.tensor(noisy_inputs.values, dtype=torch.float32).to(device)\n",
    "    synthetic2_uq[i] = synth2_model(noisy_inputs).cpu().detach().numpy().squeeze()\n",
    "print(synthetic2_uq.shape)\n",
    "\n",
    "synthetic2_uq_csh = np.zeros((n_realizations, synth2_results.shape[0]))\n",
    "for i in range(n_realizations):\n",
    "    c = synthetic2_uq[i,:,0]\n",
    "    synthetic2_uq_csh[i] = (c - c.min())/(c.max() - c.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Chevron2009', 'AkerBP Hanz Prospect', 'Synthetic Case 1', 'Synthetic Case 2']\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14,8))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    ax1.plot(chevron_uq_csh[i], chevron_results.index, color='gray', alpha=0.1)\n",
    "    ax2.plot(akerbp_uq_csh[i], akerbp_results.index, color='gray', alpha=0.1)\n",
    "    ax3.plot(synthetic1_uq_csh[i], synth1_results.index, color='gray', alpha=0.1)\n",
    "    ax4.plot(synthetic2_uq_csh[i], synth2_results.index, color='gray', alpha=0.1)\n",
    "\n",
    "ax1.plot(chevron_results['Csh_pred'], chevron_results.index, color='red')\n",
    "ax2.plot(akerbp_results['Csh_pred'], akerbp_results.index, color='red')\n",
    "ax3.plot(synth1_results['Csh_pred'], synth1_results.index, color='red')\n",
    "ax4.plot(synth2_results['Csh_pred'], synth2_results.index, color='red')\n",
    "\n",
    "[ax.set(title=titles[i], xlabel='$C_{sh}$', ylabel='Depth [ft]', xlim=(-0.05,1.05)) for i, ax in enumerate(axs)]\n",
    "[ax.invert_yaxis() for ax in axs]\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Chevron2009', 'AkerBP Hanz Prospect', 'Synthetic Case 1', 'Synthetic Case 2']\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14,8))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    ax1.plot(chevron_uq[i,:,1], chevron_results.index, color='gray', alpha=0.1)\n",
    "    ax2.plot(akerbp_uq[i,:,1], akerbp_results.index, color='gray', alpha=0.1)\n",
    "    ax3.plot(synthetic1_uq[i,:,1], synth1_results.index, color='gray', alpha=0.1)\n",
    "    ax4.plot(synthetic2_uq[i,:,1], synth2_results.index, color='gray', alpha=0.1)\n",
    "\n",
    "ax1.plot(chevron_results['Rss_pred'], chevron_results.index, color='b')\n",
    "ax2.plot(akerbp_results['Rss_pred'], akerbp_results.index, color='b')\n",
    "ax3.plot(synth1_results['Rss_pred'], synth1_results.index, color='b')\n",
    "ax4.plot(synth2_results['Rss_pred'], synth2_results.index, color='b')\n",
    "\n",
    "[ax.set(title=titles[i], xlabel='$R_{ss}$', ylabel='Depth [ft]', xscale='log') for i, ax in enumerate(axs)]\n",
    "[ax.invert_yaxis() for ax in axs]\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevron_csh_range, chevron_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(chevron_uq_csh[i], 10), np.percentile(chevron_uq_csh[i], 90)\n",
    "    p10_rss, p90_rss = np.percentile(chevron_uq[i,:,1], 10), np.percentile(chevron_uq[i,:,1], 90)\n",
    "    chevron_csh_range.append(p90_csh - p10_csh)\n",
    "    chevron_rss_range.append(p90_rss - p10_rss)\n",
    "chevron_csh_range, chevron_rss_range = np.array(chevron_csh_range), np.array(chevron_rss_range)\n",
    "\n",
    "akerbp_csh_range, akerbp_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(akerbp_uq_csh[i], 10), np.percentile(akerbp_uq_csh[i], 90)\n",
    "    p10_rss, p90_rss = np.percentile(akerbp_uq[i,:,1], 10), np.percentile(akerbp_uq[i,:,1], 90)\n",
    "    akerbp_csh_range.append(p90_csh - p10_csh)\n",
    "    akerbp_rss_range.append(p90_rss - p10_rss)\n",
    "akerbp_csh_range, akerbp_rss_range = np.array(akerbp_csh_range), np.array(akerbp_rss_range)\n",
    "\n",
    "synth1_csh_range, synth1_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(synthetic1_uq_csh[i], 10), np.percentile(synthetic1_uq_csh[i], 90)\n",
    "    p10_rss, p90_rss = np.percentile(synthetic1_uq[i,:,1], 10), np.percentile(synthetic1_uq[i,:,1], 90)\n",
    "    synth1_csh_range.append(p90_csh - p10_csh)\n",
    "    synth1_rss_range.append(p90_rss - p10_rss)\n",
    "synth1_csh_range, synth1_rss_range = np.array(synth1_csh_range), np.array(synth1_rss_range)\n",
    "\n",
    "synth2_csh_range, synth2_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(synthetic2_uq_csh[i], 10), np.percentile(synthetic2_uq_csh[i], 90)\n",
    "    p10_rss, p90_rss = np.percentile(synthetic2_uq[i,:,1], 10), np.percentile(synthetic2_uq[i,:,1], 90)\n",
    "    synth2_csh_range.append(p90_csh - p10_csh)\n",
    "    synth2_rss_range.append(p90_rss - p10_rss)\n",
    "synth2_csh_range, synth2_rss_range = np.array(synth2_csh_range), np.array(synth2_rss_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14,7))\n",
    "ax1, ax2, ax3, ax4 = axs[0]\n",
    "ax5, ax6, ax7, ax8 = axs[1]\n",
    "\n",
    "ax1.hist(chevron_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "ax2.hist(akerbp_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "ax3.hist(synth1_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "ax4.hist(synth2_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs[0]]\n",
    "[ax.set(xlabel='$U(C_{sh})$', ylabel='Frequency', title=titles[i]) for i, ax in enumerate(axs[0])]\n",
    "\n",
    "ax5.hist(chevron_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "ax6.hist(akerbp_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "ax7.hist(synth1_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "ax8.hist(synth2_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs[1]]\n",
    "[ax.set(xlabel='$U(R_{ss})$', ylabel='Frequency') for ax in axs[1]]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(14,8))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "titles = ['Chevron2009', 'AkerBP', 'Synthetic Case 1', 'Synthetic Case 2']\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    csh_chevron, rss_chevron = chevron_uq[i, :, 0], chevron_uq[i, :, 1]\n",
    "    rvsh_chevron, rhsh_chevron = chevron_results['Rvsh'].values, chevron_results['Rhsh'].values\n",
    "    rv_chevron = csh_chevron*rvsh_chevron + (1-csh_chevron)*rss_chevron\n",
    "    rh_chevron = 1/(csh_chevron/rhsh_chevron + (1-csh_chevron)/rss_chevron)\n",
    "\n",
    "    csh_akerbp, rss_akerbp = akerbp_uq[i, :, 0], akerbp_uq[i, :, 1]\n",
    "    rvsh_akerbp, rhsh_akerbp = akerbp_results['Rvsh'].values, akerbp_results['Rhsh'].values\n",
    "    rv_akerbp = csh_akerbp*rvsh_akerbp + (1-csh_akerbp)*rss_akerbp\n",
    "    rh_akerbp = 1/(csh_akerbp/rhsh_akerbp + (1-csh_akerbp)/rss_akerbp)\n",
    "\n",
    "    csh_synth1, rss_synth1 = synthetic1_uq[i, :, 0], synthetic1_uq[i, :, 1]\n",
    "    rvsh_synth1, rhsh_synth1 = synth1_results['Rvsh'].values, synth1_results['Rhsh'].values\n",
    "    rv_synth1 = csh_synth1*rvsh_synth1 + (1-csh_synth1)*rss_synth1\n",
    "    rh_synth1 = 1/(csh_synth1/rhsh_synth1 + (1-csh_synth1)/rss_synth1)\n",
    "\n",
    "    csh_synth2, rss_synth2 = synthetic2_uq[i, :, 0], synthetic2_uq[i, :, 1]\n",
    "    rvsh_synth2, rhsh_synth2 = synth2_results['Rvsh'].values, synth2_results['Rhsh'].values\n",
    "    rv_synth2 = csh_synth2*rvsh_synth2 + (1-csh_synth2)*rss_synth2\n",
    "    rh_synth2 = 1/(csh_synth2/rhsh_synth2 + (1-csh_synth2)/rss_synth2)\n",
    "    \n",
    "    ax1.plot(rv_chevron, chevron_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax1.plot(rh_chevron, chevron_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "    ax2.plot(rv_akerbp, akerbp_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax2.plot(rh_akerbp, akerbp_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "    ax3.plot(rv_synth1, synth1_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax3.plot(rh_synth1, synth1_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "    ax4.plot(rv_synth2, synth2_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax4.plot(rh_synth2, synth2_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "ax1.plot(chevron_results['Rv'], chevron_results.index, c='k', lw=1, ls='--')\n",
    "ax1.plot(chevron_results['Rh'], chevron_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "ax2.plot(akerbp_results['Rv'], akerbp_results.index, c='k', lw=1, ls='--')\n",
    "ax2.plot(akerbp_results['Rh'], akerbp_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "ax3.plot(synth1_results['Rv'], synth1_results.index, c='k', lw=1, ls='--')\n",
    "ax3.plot(synth1_results['Rh'], synth1_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "ax4.plot(synth2_results['Rv'], synth2_results.index, c='k', lw=1, ls='--')\n",
    "ax4.plot(synth2_results['Rh'], synth2_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "[ax.set_title(titles[i]) for i, ax in enumerate(axs)]\n",
    "[ax.set(xscale='log', ylabel='Depth [ft]', xlabel='$R$ $[\\Omega\\cdot m]$', xlim=(1e-2, 1e2)) for ax in axs]\n",
    "[ax.grid(True, which='both') for ax in axs]\n",
    "ax1.invert_yaxis(); ax2.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic inverison, uncertainty quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations = 100\n",
    "\n",
    "chevron_q_uq = np.zeros((n_realizations, data1.shape[0], 2))\n",
    "for i in tqdm(range(n_realizations)):\n",
    "    rv, rh, rvsh, rhsh = data1['Rv'], data1['Rh'], data1['Rvsh'], data1['Rhsh']\n",
    "    inputs = np.array([rv, rh]).T\n",
    "    noisy_inputs = inputs + noise_level*np.random.lognormal(0, 1, size=(inputs.shape[0], 2))\n",
    "    noisy_data   = np.concatenate([noisy_inputs, np.array([rvsh, rhsh]).T], axis=1)\n",
    "    chevron_q_uq[i] = newton_inversion(pd.DataFrame(noisy_data, columns=[['Rv','Rh','Rvsh','Rhsh']]))\n",
    "\n",
    "akerbp_q_uq = np.zeros((n_realizations, data2.shape[0], 2))\n",
    "for i in tqdm(range(n_realizations)):\n",
    "    rv, rh, rvsh, rhsh = data2['Rv'], data2['Rh'], data2['Rvsh'], data2['Rhsh']\n",
    "    inputs = np.array([rv, rh]).T\n",
    "    noisy_inputs = inputs + noise_level*np.random.lognormal(0, 1, size=(inputs.shape[0], 2))\n",
    "    noisy_data   = np.concatenate([noisy_inputs, np.array([rvsh, rhsh]).T], axis=1)\n",
    "    akerbp_q_uq[i] = newton_inversion(pd.DataFrame(noisy_data, columns=[['Rv','Rh','Rvsh','Rhsh']]))\n",
    "\n",
    "synth1_q_uq = np.zeros((n_realizations, data3.shape[0], 2))\n",
    "for i in tqdm(range(n_realizations)):\n",
    "    rv, rh, rvsh, rhsh = data3['Rv'], data3['Rh'], data3['Rvsh'], data3['Rhsh']\n",
    "    inputs = np.array([rv, rh]).T\n",
    "    noisy_inputs = inputs + noise_level*np.random.lognormal(0, 1, size=(inputs.shape[0], 2))\n",
    "    noisy_data   = np.concatenate([noisy_inputs, np.array([rvsh, rhsh]).T], axis=1)\n",
    "    synth1_q_uq[i] = newton_inversion(pd.DataFrame(noisy_data, columns=[['Rv','Rh','Rvsh','Rhsh']]))\n",
    "\n",
    "synth2_q_uq = np.zeros((n_realizations, data4.shape[0], 2))\n",
    "for i in tqdm(range(n_realizations)):\n",
    "    rv, rh, rvsh, rhsh = data4['Rv'], data4['Rh'], data4['Rvsh'], data4['Rhsh']\n",
    "    inputs = np.array([rv, rh]).T\n",
    "    noisy_inputs = inputs + noise_level*np.random.lognormal(0, 1, size=(inputs.shape[0], 2))\n",
    "    noisy_data   = np.concatenate([noisy_inputs, np.array([rvsh, rhsh]).T], axis=1)\n",
    "    synth2_q_uq[i] = newton_inversion(pd.DataFrame(noisy_data, columns=[['Rv','Rh','Rvsh','Rhsh']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(14,8))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "titles = ['Chevron2009', 'AkerBP', 'Synthetic Case 1', 'Synthetic Case 2']\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    ax1.plot(chevron_q_uq[i,:,0], data1.index, color='gray', alpha=0.1)\n",
    "    ax2.plot(akerbp_q_uq[i,:,0], data2.index, color='gray', alpha=0.1)\n",
    "    ax3.plot(synth1_q_uq[i,:,0], data3.index, color='gray', alpha=0.1)\n",
    "    ax4.plot(synth2_q_uq[i,:,0], data4.index, color='gray', alpha=0.1)\n",
    "\n",
    "ax1.plot(chevron_results['Csh_q'], chevron_results.index, color='red')\n",
    "ax2.plot(akerbp_results['Csh_q'], akerbp_results.index, color='red')\n",
    "ax3.plot(synth1_results['Csh_q'], synth1_results.index, color='red')\n",
    "ax4.plot(synth2_results['Csh_q'], synth2_results.index, color='red')\n",
    "\n",
    "[ax.set(title=titles[i], xlabel='$C_{sh}$', ylabel='Depth [ft]') for i, ax in enumerate(axs)]\n",
    "[ax.invert_yaxis() for ax in axs]\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(14,8))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    ax1.plot(chevron_q_uq[i,:,1], data1.index, color='gray', alpha=0.1)\n",
    "    ax2.plot(akerbp_q_uq[i,:,1], data2.index, color='gray', alpha=0.1)\n",
    "    ax3.plot(synth1_q_uq[i,:,1], data3.index, color='gray', alpha=0.1)\n",
    "    ax4.plot(synth2_q_uq[i,:,1], data4.index, color='gray', alpha=0.1)\n",
    "\n",
    "ax1.plot(chevron_results['Rss_q'], chevron_results.index, color='blue')\n",
    "ax2.plot(akerbp_results['Rss_q'], akerbp_results.index, color='blue')\n",
    "ax3.plot(synth1_results['Rss_q'], synth1_results.index, color='blue')\n",
    "ax4.plot(synth2_results['Rss_q'], synth2_results.index, color='blue')\n",
    "\n",
    "[ax.set(title=titles[i], xlabel='$R_{ss}$', ylabel='Depth [ft]', xscale='log') for i, ax in enumerate(axs)]\n",
    "[ax.invert_yaxis() for ax in axs]\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevron_q_csh_range, chevron_q_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(chevron_q_uq[i,:,0], 10), np.percentile(chevron_q_uq[i,:,0], 90)\n",
    "    p10_rss, p90_rss = np.percentile(chevron_q_uq[i,:,1], 10), np.percentile(chevron_q_uq[i,:,1], 90)\n",
    "    chevron_q_csh_range.append(p90_csh - p10_csh)\n",
    "    chevron_q_rss_range.append(p90_rss - p10_rss)\n",
    "chevron_q_csh_range, chevron_q_rss_range = np.array(chevron_q_csh_range), np.array(chevron_q_rss_range)\n",
    "\n",
    "akerbp_q_csh_range, akerbp_q_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(akerbp_q_uq[i,:,0], 10), np.percentile(akerbp_q_uq[i,:,0], 90)\n",
    "    p10_rss, p90_rss = np.percentile(akerbp_q_uq[i,:,1], 10), np.percentile(akerbp_q_uq[i,:,1], 90)\n",
    "    akerbp_q_csh_range.append(p90_csh - p10_csh)\n",
    "    akerbp_q_rss_range.append(p90_rss - p10_rss)\n",
    "akerbp_q_csh_range, akerbp_q_rss_range = np.array(akerbp_q_csh_range), np.array(akerbp_q_rss_range)\n",
    "\n",
    "synth1_q_csh_range, synth1_q_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(synth1_q_uq[i,:,0], 10), np.percentile(synth1_q_uq[i,:,0], 90)\n",
    "    p10_rss, p90_rss = np.percentile(synth1_q_uq[i,:,1], 10), np.percentile(synth1_q_uq[i,:,1], 90)\n",
    "    synth1_q_csh_range.append(p90_csh - p10_csh)\n",
    "    synth1_q_rss_range.append(p90_rss - p10_rss)\n",
    "synth1_q_csh_range, synth1_q_rss_range = np.array(synth1_q_csh_range), np.array(synth1_q_rss_range)\n",
    "\n",
    "synth2_q_csh_range, synth2_q_rss_range = [], []\n",
    "for i in range(n_realizations):\n",
    "    p10_csh, p90_csh = np.percentile(synth2_q_uq[i,:,0], 10), np.percentile(synth2_q_uq[i,:,0], 90)\n",
    "    p10_rss, p90_rss = np.percentile(synth2_q_uq[i,:,1], 10), np.percentile(synth2_q_uq[i,:,1], 90)\n",
    "    synth2_q_csh_range.append(p90_csh - p10_csh)\n",
    "    synth2_q_rss_range.append(p90_rss - p10_rss)\n",
    "synth2_q_csh_range, synth2_q_rss_range = np.array(synth2_q_csh_range), np.array(synth2_q_rss_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14,7))\n",
    "ax1, ax2, ax3, ax4 = axs[0]\n",
    "ax5, ax6, ax7, ax8 = axs[1]\n",
    "\n",
    "ax1.hist(chevron_q_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "ax2.hist(akerbp_q_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "ax3.hist(synth1_q_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "ax4.hist(synth2_q_csh_range, bins=20, color='firebrick', alpha=0.75, edgecolor='gray')\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs[0]]\n",
    "[ax.set(xlabel='$U(C_{sh})$', ylabel='Frequency', title=titles[i]) for i, ax in enumerate(axs[0])]\n",
    "\n",
    "ax5.hist(chevron_q_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "ax6.hist(akerbp_q_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "ax7.hist(synth1_q_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "ax8.hist(synth2_q_rss_range, bins=20, color='dodgerblue', alpha=0.75, edgecolor='gray')\n",
    "[ax.grid(True, which='both', alpha=0.5) for ax in axs[1]]\n",
    "[ax.set(xlabel='$U(R_{ss})$', ylabel='Frequency') for ax in axs[1]]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(14,8))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "titles = ['Chevron2009', 'AkerBP', 'Synthetic Case 1', 'Synthetic Case 2']\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    csh_chevron, rss_chevron = chevron_q_uq[i, :, 0], chevron_q_uq[i, :, 1]\n",
    "    rvsh_chevron, rhsh_chevron = chevron_results['Rvsh'].values, chevron_results['Rhsh'].values\n",
    "    rv_chevron = csh_chevron*rvsh_chevron + (1-csh_chevron)*rss_chevron\n",
    "    rh_chevron = 1/(csh_chevron/rhsh_chevron + (1-csh_chevron)/rss_chevron)\n",
    "\n",
    "    csh_akerbp, rss_akerbp = akerbp_q_uq[i, :, 0], akerbp_q_uq[i, :, 1]\n",
    "    rvsh_akerbp, rhsh_akerbp = akerbp_results['Rvsh'].values, akerbp_results['Rhsh'].values\n",
    "    rv_akerbp = csh_akerbp*rvsh_akerbp + (1-csh_akerbp)*rss_akerbp\n",
    "    rh_akerbp = 1/(csh_akerbp/rhsh_akerbp + (1-csh_akerbp)/rss_akerbp)\n",
    "\n",
    "    csh_synth1, rss_synth1 = synth1_q_uq[i, :, 0], synth1_q_uq[i, :, 1]\n",
    "    rvsh_synth1, rhsh_synth1 = synth1_results['Rvsh'].values, synth1_results['Rhsh'].values\n",
    "    rv_synth1 = csh_synth1*rvsh_synth1 + (1-csh_synth1)*rss_synth1\n",
    "    rh_synth1 = 1/(csh_synth1/rhsh_synth1 + (1-csh_synth1)/rss_synth1)\n",
    "\n",
    "    csh_synth2, rss_synth2 = synth2_q_uq[i, :, 0], synth2_q_uq[i, :, 1]\n",
    "    rvsh_synth2, rhsh_synth2 = synth2_results['Rvsh'].values, synth2_results['Rhsh'].values\n",
    "    rv_synth2 = csh_synth2*rvsh_synth2 + (1-csh_synth2)*rss_synth2\n",
    "    rh_synth2 = 1/(csh_synth2/rhsh_synth2 + (1-csh_synth2)/rss_synth2)\n",
    "    \n",
    "    ax1.plot(rv_chevron, chevron_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax1.plot(rh_chevron, chevron_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "    ax2.plot(rv_akerbp, akerbp_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax2.plot(rh_akerbp, akerbp_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "    ax3.plot(rv_synth1, synth1_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax3.plot(rh_synth1, synth1_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "    ax4.plot(rv_synth2, synth2_results.index, c='rosybrown', alpha=0.1)\n",
    "    ax4.plot(rh_synth2, synth2_results.index, c='lightsteelblue', alpha=0.1)\n",
    "\n",
    "ax1.plot(chevron_results['Rv'], chevron_results.index, c='k', lw=1, ls='--')\n",
    "ax1.plot(chevron_results['Rh'], chevron_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "ax2.plot(akerbp_results['Rv'], akerbp_results.index, c='k', lw=1, ls='--')\n",
    "ax2.plot(akerbp_results['Rh'], akerbp_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "ax3.plot(synth1_results['Rv'], synth1_results.index, c='k', lw=1, ls='--')\n",
    "ax3.plot(synth1_results['Rh'], synth1_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "ax4.plot(synth2_results['Rv'], synth2_results.index, c='k', lw=1, ls='--')\n",
    "ax4.plot(synth2_results['Rh'], synth2_results.index, c='k', lw=1, ls='-.')\n",
    "\n",
    "[ax.set_title(titles[i]) for i, ax in enumerate(axs)]\n",
    "[ax.set(xscale='log', ylabel='Depth [ft]', xlabel='$R$ $[\\Omega\\cdot m]$', xlim=(1e-2, 1e2)) for ax in axs]\n",
    "[ax.grid(True, which='both') for ax in axs]\n",
    "ax1.invert_yaxis(); ax2.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
