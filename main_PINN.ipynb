{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated anisotropic resistivity inversion for efficient formation evaluation and uncertainty quantification\n",
    "\n",
    "### Misael M. Morales, Ali Eghbali, Oriyomi Raheem, Michael Pyrcz, Carlos Torres-Verdin\n",
    "***\n",
    "## Machine Learning-based Inversion\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "check_torch()\n",
    "case1, case2, synthetic1, synthetic2 = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Physics-informed neural network inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResInvPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResInvPINN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def constraints(self, x):\n",
    "        c, s = x[:, 0], x[:, 1]\n",
    "        c = nn.Sigmoid()(c)\n",
    "        return torch.stack([c, s], dim=-1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.constraints(x)\n",
    "        return x\n",
    "    \n",
    "class ResInvLoss(nn.Module):\n",
    "    def __init__(self, Rvsh=10, Rhsh=1, lambda_reg=1e-5, lambda_p=2):\n",
    "        super(ResInvLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lambda_p = lambda_p\n",
    "        self.Rvsh = Rvsh\n",
    "        self.Rhsh = Rhsh\n",
    "\n",
    "    def forward(self, inputs, outputs):\n",
    "        Rv_true = inputs[:, 0]\n",
    "        Rh_true = inputs[:, 1]\n",
    "\n",
    "        Csh_pred = outputs[:, 0]\n",
    "        Rss_pred = outputs[:, 1]\n",
    "\n",
    "        eq1 = (Csh_pred*self.Rvsh + (1-Csh_pred)*Rss_pred) - (Rv_true)\n",
    "        eq2 = 1/(Csh_pred/self.Rhsh + (1-Csh_pred)/Rss_pred) - (Rh_true)\n",
    "        eqs = torch.stack([eq1, eq2], dim=-1)\n",
    "\n",
    "        wd1, wd2 = 1/Rv_true, 1*Rh_true\n",
    "        Wdm = torch.stack([wd1, wd2], dim=-1)\n",
    "\n",
    "        costf = torch.norm(torch.matmul(Wdm.T, eqs), p=2)\n",
    "        regPa = self.lambda_reg*torch.norm(outputs, p=self.lambda_p)\n",
    "\n",
    "        return  costf + regPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_keys = ['CALI', 'AT10','AT30','AT60','AT90','GR','RV72H_1D_FLT','RH72H_1D_FLT']\n",
    "d = lasio.read('cases/well1.las').df()[w1_keys].dropna()\n",
    "column_names = ['CALI', 'AT10', 'AT30', 'AT60', 'AT90', 'GR', 'Rv', 'Rh']\n",
    "\n",
    "zstart = int(np.argwhere(d.index==9720).squeeze())\n",
    "zend   = int(np.argwhere(d.index==10110).squeeze())\n",
    "\n",
    "data      = d.rename(columns=dict(zip(d.columns, column_names))).iloc[zstart:zend]\n",
    "res_aniso = data[['Rv', 'Rh']]\n",
    "\n",
    "Rvsh_true = 2.813\n",
    "Rhsh_true = 0.775\n",
    "\n",
    "inputs = torch.tensor(res_aniso.values, dtype=torch.float32)\n",
    "print('Inputs: {}'.format(inputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset        = TensorDataset(inputs)\n",
    "train_percent  = 0.8\n",
    "xtrain, xvalid = random_split(dataset, [int(train_percent*len(dataset)), len(dataset)-int(train_percent*len(dataset))])\n",
    "print('X_train: {} | X_valid: {}'.format(len(xtrain), len(xvalid)))\n",
    "\n",
    "trainloader    = DataLoader(xtrain, batch_size=32, shuffle=True)\n",
    "validloader    = DataLoader(xvalid, batch_size=32, shuffle=True)\n",
    "\n",
    "pinn       = ResInvPINN()\n",
    "criterion  = ResInvLoss(Rvsh=Rvsh_true, Rhsh=Rhsh_true, lambda_reg=1e-5, lambda_p=1)\n",
    "optimizer  = torch.optim.Adam(params=pinn.parameters(), lr=1e-3)\n",
    "\n",
    "epochs, monitor = 301, 100\n",
    "train_loss, valid_loss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    epoch_train_loss = []\n",
    "    pinn.train()\n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        x = batch[0]\n",
    "        y = pinn(x)\n",
    "        loss = criterion(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss.append(loss.item())\n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    # validation\n",
    "    pinn.eval()\n",
    "    epoch_valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        x = next(iter(validloader))[0]\n",
    "        y = pinn(x)\n",
    "        loss = criterion(x, y)\n",
    "        epoch_valid_loss.append(loss.item())\n",
    "    valid_loss.append(np.mean(epoch_valid_loss))\n",
    "    # progress\n",
    "    if epoch % monitor == 0:\n",
    "        print('Epoch: {} | Loss: {:.4f} | Valid Loss: {:.4f}'.format(epoch, train_loss[-1], valid_loss[-1]))\n",
    "losses = (train_loss, valid_loss)\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pinn(inputs[:,:2]).detach().numpy().squeeze()\n",
    "Csh_pred, Rss_pred = [y_pred[:, i] for i in range(y_pred.shape[1])]\n",
    "print('Csh: min={:.3f} | max={:.3f}'.format(Csh_pred.min(), Csh_pred.max()))\n",
    "\n",
    "Rv_true = res_aniso['Rv'].values\n",
    "Rh_true = res_aniso['Rh'].values\n",
    "\n",
    "Rv_sim = (Csh_pred*Rvsh_true + (1-Csh_pred)*Rss_pred)\n",
    "Rh_sim = 1/(Csh_pred/Rhsh_true + (1-Csh_pred)/Rss_pred)\n",
    "\n",
    "Rv_err = np.abs((Rv_sim - Rv_true)/Rv_true) * 100\n",
    "Rh_err = np.abs((Rh_sim - Rh_true)/Rh_true) * 100\n",
    "\n",
    "pinn_sol = pd.DataFrame({'Csh_pred':Csh_pred, 'Rss_pred':Rss_pred, \n",
    "                         'Rvsh':Rhsh_true, 'Rhsh':Rhsh_true,\n",
    "                         'Rv_sim':Rv_sim, 'Rh_sim':Rh_sim,\n",
    "                         'Rv_err':Rv_err, 'Rh_err':Rh_err}, index=res_aniso.index)\n",
    "\n",
    "results = pd.concat([data, pinn_sol], axis=1)\n",
    "results.to_csv('pinn_solution.csv', index=True)\n",
    "\n",
    "error_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pinn_results(results, figsize=(12.5,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientbased_results = pd.read_csv('results/gradient_based_solution_Chevron.csv', index_col=0)\n",
    "plot_pinn_gb_comparison(results, gradientbased_results, figsize=(12.5,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
